<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Networks学习笔记, 杂货铺, Peyton">
    <meta name="description" content="从来没有真正的绝境，只有心灵的迷途">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Networks学习笔记 | Peytonの杂货铺</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Peytonの杂货铺" type="application/atom+xml">
</head>



   <style>
    body{
       background-image: url(/medias/background.jpg);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>



<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Peytonの杂货铺</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle-o" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Peytonの杂货铺</div>
        <div class="logo-desc">
            
            从来没有真正的绝境，只有心灵的迷途
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle-o"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/11.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Networks学习笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Network-Science/">
                                <span class="chip bg-color">Network Science</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Network-Science/" class="post-category">
                                Network Science
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-07-21
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    31 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        <link rel="stylesheet" href="/libs/prism/prism.css">
        <!-- 代码块折行 -->
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Networks学习笔记"><a href="#Networks学习笔记" class="headerlink" title="Networks学习笔记"></a>Networks学习笔记</h1><h2 id="第二部分——网络理论基础"><a href="#第二部分——网络理论基础" class="headerlink" title="第二部分——网络理论基础"></a>第二部分——网络理论基础</h2><h3 id="1-网络数学模型"><a href="#1-网络数学模型" class="headerlink" title="1.网络数学模型"></a>1.网络数学模型</h3><h4 id="1-无环图-Acyclic-Network"><a href="#1-无环图-Acyclic-Network" class="headerlink" title="1) 无环图(Acyclic Network)"></a>1) 无环图(Acyclic Network)</h4><ul>
<li><p>Acyclic Network：一些有向网络中不含环的部分。（典型的如引文网络）</p>
</li>
<li><p>由于self-edge也是环，所以Acyclic Network不含自环。</p>
</li>
<li><p>Acyclic Network中至少一个节点仅有进入的连边而没有走出的连边。（反证法+游走法证明）</p>
</li>
<li><p>Acyclic Network所有边都可以画成向下指(point downward)的形式。</p>
</li>
<li><p>可视化Acyclic Network的方法：</p>
</li>
</ul>
<blockquote>
<p>First, we search through the network for a node with no outgoing edges. There could be more than one such node, in which case we choose whichever one we like. Let us call this node 1. We now remove node 1 from the network, along with any edges attached to it, then we repeat the process, finding another node with no outgoing edges in the remaining network. We call this node 2, remove it from the network along with its edges, and so forth. After all nodes have been numbered and removed, we put the network back together again and draw a picture of it by placing the nodes in numerical order from bottom to top of the page and then drawing the directed edges in the appropriate positions between them. Every node has outgoing edges only to lower numbered nodes—those drawn below it in the picture—because it had no outgoing edges at the time it was removed from the network, so all its original outgoing edges (if it ever had any) must have been connected to nodes that were removed earlier. Thus all edges in the final picture must be pointing downward.</p>
</blockquote>
<ul>
<li>无环图和有环图检测算法：</li>
</ul>
<blockquote>
<ol>
<li>Find a node with no outgoing edges. </li>
<li>If no such node exists, the network is cyclic. Otherwise, if such a node does exist, remove it and all its ingoing edges from the network.</li>
<li>If all nodes have been removed, the network is acyclic. Otherwise, go back to step 1.</li>
</ol>
</blockquote>
<h4 id="2-超图-Hypergraphs"><a href="#2-超图-Hypergraphs" class="headerlink" title="2) 超图(Hypergraphs)"></a>2) 超图(Hypergraphs)</h4><ul>
<li>hyperedges：连接超过两个节点的边。</li>
<li>超图可以有二分网络的表现形式。</li>
</ul>
<h4 id="3-二分图-Bipartite-Network"><a href="#3-二分图-Bipartite-Network" class="headerlink" title="3) 二分图(Bipartite Network)"></a>3) 二分图(Bipartite Network)</h4><ul>
<li>二分图有两类节点，其中连边只存在两类节点之间。</li>
<li>有向的二分图在原理上也是可能存在的。（代谢网络）</li>
</ul>
<h4 id="4-关联矩阵-Incidence-Matrix-和网络映射-Network-Projection"><a href="#4-关联矩阵-Incidence-Matrix-和网络映射-Network-Projection" class="headerlink" title="4)关联矩阵(Incidence Matrix)和网络映射(Network Projection)"></a>4)关联矩阵(Incidence Matrix)和网络映射(Network Projection)</h4><ul>
<li><p>关联矩阵：二分图邻接矩阵的等价形式。（0/1归属形式表示）</p>
</li>
<li><p>二分图是two-mode的网络映射，但我们可以从两类节点分别考虑而将二分图变成两个one-mode的网络映射：如果同类节点中的两个节点都连接另一类节点中的一个，那么在one-mode映射图中该两个节点之间存在连边，反之不存在。因此在one-mode映射图中只存在一种类别的节点。</p>
</li>
</ul>
<h4 id="5-多层网络-Multilayer-Network"><a href="#5-多层网络-Multilayer-Network" class="headerlink" title="5) 多层网络(Multilayer Network)"></a>5) 多层网络(Multilayer Network)</h4><ul>
<li><p>多层网络是多个独立的网络，每层代表一种特定类型的节点和它们的连接，以及网络之间的互连边。</p>
</li>
<li><p>Multiplex Network是Multilayer Network的特殊情况，即Multiplex Network的每一层节点都表示同一类对象。</p>
</li>
</ul>
<h4 id="6-树-Tree"><a href="#6-树-Tree" class="headerlink" title="6) 树(Tree)"></a>6) 树(Tree)</h4><ul>
<li>树为不包括环的连通无向网络；也可以由两个或两个以上的部分(components)组成，它们之间互不相连，如果单独的部分没有环路，它也被称为树。如果网络的所有部分都是树，那么完整的网络就叫做森林(forest)。</li>
<li>任何两个节点对之间只存在一条路径。</li>
<li>n个节点的树总是刚好有n-1条连边。反之亦然，任何有n个节点和n - 1条连边的连通网络是树。 </li>
<li>在n个节点上具有最少边数的连通网络始终是树。</li>
</ul>
<h4 id="7-平面图-Planar-Graphs"><a href="#7-平面图-Planar-Graphs" class="headerlink" title="7) 平面图(Planar Graphs)"></a>7) 平面图(Planar Graphs)</h4><ul>
<li>平面网络是指可以在平面上画出没有任何边交叉的网络。</li>
<li>所有的树都是planar图。</li>
<li>平面图的例子：路网络、美国州的邻接图。</li>
<li>四色定理：对平面网络的节点进行着色，使由一条边连接的两个节点颜色不相同。关于总共需要的颜色数我们称之为chromatic number(色数)，定理证明了平面网络的色数永远是4或更少。</li>
<li>判定平面网络的方法：Kuratowski’s theorem（库拉托夫斯基定理）。</li>
</ul>
<h4 id="8-度-Degree"><a href="#8-度-Degree" class="headerlink" title="8) 度(Degree)"></a>8) 度(Degree)</h4><ul>
<li>无向网络中一个节点的度是与它相连的边的数量。</li>
<li>无向网络的平均度等于该网络邻接矩阵所有项求和除以节点数。</li>
<li>所有节点的度数都相同的网络叫做regular networks(正则图)。                                                  </li>
</ul>
<h4 id="9-密度-Density-与稀疏度-Sparsity"><a href="#9-密度-Density-与稀疏度-Sparsity" class="headerlink" title="9) 密度(Density)与稀疏度(Sparsity)"></a>9) 密度(Density)与稀疏度(Sparsity)</h4><ul>
<li>网络的密度等于连边数与最大连边数的比值。其可以被看做是一对节点连接的概率，其大小为0到1之间的数。</li>
<li>当节点数n变大时，如果密度ρ保持不为零，则网络是稠密的。当网络的密度ρ→0在大n的极限上是稀疏的，并且邻接矩阵中非零元素的比例趋于零。</li>
<li>网络的平均度=网络密度×(n-1)≈网络密度×n。</li>
</ul>
<h4 id="10-有向网络-Directed-Network"><a href="#10-有向网络-Directed-Network" class="headerlink" title="10) 有向网络(Directed Network)"></a>10) 有向网络(Directed Network)</h4><ul>
<li>度数分为出度和入度。</li>
<li>有向网络的连边总数为邻接矩阵中的所有项求和。有向网络的平均度与无向网络的平均度存在2倍关系。</li>
</ul>
<h4 id="11-游走-Walks-和路径-Paths"><a href="#11-游走-Walks-和路径-Paths" class="headerlink" title="11) 游走(Walks)和路径(Paths)"></a>11) 游走(Walks)和路径(Paths)</h4><ul>
<li><p>A walk in a network is any sequence of nodes such that every consecutive pair of nodes in the sequence is connected by an edge.</p>
</li>
<li><p>Walks that do not intersect themselves are called <strong>paths</strong> or self-avoiding walks, and are important in many areas of network theory.</p>
</li>
<li><p>The length of a walk in a network is the number of edges traversed along the walk (not the number of nodes).</p>
</li>
<li><p>不同Walks长度的数目可以通过邻接矩阵的不同阶次项求和得到。(p131)</p>
</li>
</ul>
<h4 id="12-最短路径-Shortest-Paths"><a href="#12-最短路径-Shortest-Paths" class="headerlink" title="12) 最短路径(Shortest Paths)"></a>12) 最短路径(Shortest Paths)</h4><ul>
<li><p>A shortest path in a network, also sometimes called a geodesic path, is the shortest walk between a given pair of nodes.</p>
</li>
<li><p>Among all shortest paths between every pair of nodes in the network for which a path actually exists, the <strong>diameter</strong> is the length of the longest one.</p>
</li>
</ul>
<h4 id="13-连通片-Components"><a href="#13-连通片-Components" class="headerlink" title="13) 连通片(Components)"></a>13) 连通片(Components)</h4><ul>
<li><p>Technically, a component is a subset of the nodes of a network such that there exists at least one path from each member of that subset to each other member, and such that no other node in the network can be added to the subset while preserving this property. (Subsets like this, to which no other node can be added while preserving a given property, are called maximal subsets.)</p>
</li>
<li><p>A network in which all nodes belong to the same single component is said to be connected.</p>
</li>
<li><p>Two nodes are in the same <strong>weakly connected</strong> <strong>component</strong> if they are connected by one or more paths through the network, where paths are allowed to go either way along any edge.</p>
</li>
<li><p>we define A and B to be connected if and only if there exists a directed path both from A to B and from B to A. In that case, A and B are said to be <strong>strongly connected</strong>. We can define components for a directed network using this definition of connection and these are called strongly connected components.</p>
</li>
<li><p>Out-components: an out-component is the set of nodes that are reachable via directed paths starting from a specified node A, and including A itself. (Out-component is a property of both the network structure and the starting node)</p>
</li>
<li><p>In both the in-component and the out-component ofAis necessarily also in its strongly connected component.</p>
</li>
</ul>
<h4 id="14-独立路径-Independent-paths-连通度-Connectivity-和割集-Cut-Sets"><a href="#14-独立路径-Independent-paths-连通度-Connectivity-和割集-Cut-Sets" class="headerlink" title="14) 独立路径(Independent paths),连通度(Connectivity)和割集(Cut Sets)"></a>14) 独立路径(Independent paths),连通度(Connectivity)和割集(Cut Sets)</h4><ul>
<li><p>There are two species of independent path: <strong>edge-independent</strong> and <strong>node-independent</strong>. Two paths connecting a given pair of nodes are edge-independent if they share no edges. Two paths are node-independent if they share no nodes, other than their starting and ending nodes.</p>
</li>
<li><p>The number of independent paths (either edge- or node-independent) from A to B cannot exceed A’s degree, since every path must leave node A along a different edge. Similarly, the number of paths cannot exceed B’s degree either.</p>
</li>
<li><p>The number of independent paths between a pair of nodes is called the connectivity of the nodes.</p>
</li>
<li><p><strong>A cut set,</strong> or more properly a node cut set, is a set of nodes whose removal (along with the adjacent edges) will disconnect a specified pair of nodes. (p139)</p>
</li>
<li><p><strong>Menger’s theorem</strong> says that the size of the minimum cut set between any pair of nodes in a network is equal to the number of independent paths between the same nodes. (p139)</p>
</li>
<li><p><strong>Menger’s theorem and the max-flow/min-cut theorem</strong> tell us that for a pair of nodes in an undirected network three quantities are all numerically equal to each other: the edge connectivity of the pair (i.e., the number of edge-independent paths connecting them), the size of the minimum edge cut set (i.e., the number of edges that must be removed to disconnect them), and the maximum flow between the nodes expressed as a multiple of the maximum flow along each individual edge. (p140)</p>
</li>
</ul>
<h4 id="15-加权网络上的最大流量与割集-Maximum-flows-and-cut-sets-on-weighted-networks"><a href="#15-加权网络上的最大流量与割集-Maximum-flows-and-cut-sets-on-weighted-networks" class="headerlink" title="15) 加权网络上的最大流量与割集 (Maximum flows and cut sets on weighted networks)"></a>15) 加权网络上的最大流量与割集 (Maximum flows and cut sets on weighted networks)</h4><ul>
<li><p><strong>A minimum edge cut set</strong> is defined as being a cut set such that the sum of the weights on the edges of the set has the minimum possible value.</p>
</li>
<li><p>Maximum flow between a given pair of nodes in a network is equal to the sum of the weights on the edges of the minimum edge cut set that separates the same pair of nodes. (p141)</p>
</li>
</ul>
<h4 id="16-图拉普拉斯-Graph-Laplacian"><a href="#16-图拉普拉斯-Graph-Laplacian" class="headerlink" title="16) 图拉普拉斯 (Graph Laplacian)"></a>16) 图拉普拉斯 (Graph Laplacian)</h4><ul>
<li>The graph Laplacian for a simple undirected, unweighted network is an <code>n × n</code> symmetric matrix <code>L</code> with elements</li>
</ul>
<script type="math/tex; mode=display">
L_{ij}=
\begin{cases}
k_i, \ \ \ if \ i=j \\
-1,  \ if \ i \ne j \ and \ there \ is \ an\ edge \ between \ nodes \ i \ and \ j \\
0 ,\ \ \ \ otherwise
\end{cases}</script><ul>
<li>Another way to write the same thing would be $L_{ij}=k_i\delta_{ij}-A_{ij}$. And $\delta_{ij}$ is <code>Kronecker delta</code>.</li>
<li><p>We can write $L$ in matrix form as <strong>$L=D-A$</strong>, where $D$ is the diagonal matrix with the node degrees along its diagonal.</p>
</li>
<li><p>One can also write a graph Laplacian for weighted networks.</p>
</li>
<li>One can also treat multigraphs in the same way.</li>
<li>No natural extension of the graph Laplacian to networks with self-edges or, more importantly, to directed networks. The Laplacian is only useful for the undirected case.</li>
</ul>
<h4 id="17-图拉普拉斯应用——图分割-Graph-Partitioning"><a href="#17-图拉普拉斯应用——图分割-Graph-Partitioning" class="headerlink" title="17) 图拉普拉斯应用——图分割 (Graph Partitioning)"></a>17) 图拉普拉斯应用——图分割 (Graph Partitioning)</h4><ul>
<li><p>Graph partitioning is the task of dividing the nodes of a network into a set of groups of given sizes so as to minimize the number of edges running between the groups. (p143)</p>
</li>
<li><p>The number of edges $R$ running between the two groups, also called the <code>cut size</code>: $R = \frac{1}{2} \Sigma_{i,j\ in\ different\ groups} A_{ij}$. We define a set of quantities $s_i$:</p>
<script type="math/tex; mode=display">
s_{i}=
\begin{cases}
+1 & if\ node\ i\ belong\ to\ group\ 1 \\
-1 & if\ node\ i\ belong\ to\ group\ 2 \\
\end{cases}</script><p>Then</p>
<script type="math/tex; mode=display">
\frac{1}{2}(1-s_is_j)=
\begin{cases}
1 & if\ i\ and\ j\ are\ in\ different\ groups\\
0 & if\ i\ and\ j\ are\ in\ the\ same\ groups\\
\end{cases}</script><p>which allows us to rewrite $R$:</p>
<script type="math/tex; mode=display">
R=\frac{1}{4}\Sigma_{ij}A_{ij}(1-s_is_j)</script><p>The first term in the sum is </p>
<script type="math/tex; mode=display">
\Sigma_{ij}A_{ij}=\Sigma_ik_i=\Sigma_ik_is^2_i=\Sigma_{ij}k_i\delta_{ij}s_is_j</script><p>Substituting back (4) we then find that</p>
<script type="math/tex; mode=display">
R=\frac{1}{4}\Sigma_{ij}(k_i\delta_{ij}-A_{ij})s_is_j=\frac{1}{4}\Sigma_{ij}L_{ij}s_is_j</script><p>We can be written in matrix form as </p>
<script type="math/tex; mode=display">
R=\frac{1}{4}s^TLs</script></li>
<li><p>The matrix $L$ specifies the structure of our network, the vector s defines a division of that network into groups, and our goal is to find the vectors that minimizes the cut size for given $L$. We can makes use of the eigenvectors of the graph Laplacian to rapidly find good divisions of the network.</p>
</li>
</ul>
<h4 id="18-图拉普拉斯应用——网络可视化-Network-Visualization"><a href="#18-图拉普拉斯应用——网络可视化-Network-Visualization" class="headerlink" title="18) 图拉普拉斯应用——网络可视化 (Network Visualization)"></a>18) 图拉普拉斯应用——网络可视化 (Network Visualization)</h4><ul>
<li>The distance between nodes i and j in our simple one-dimensional model is $|x_i−x_j|$ and the squared distance is $(x_i−x_j)^2$. The sum $∆^2$ of the squared distances for all node pairs connected by an edge is then<script type="math/tex; mode=display">
\Delta^2=\frac{1}{2}\Sigma_{ij}A_{ij}(x_i-x_j)^2</script>Expanding this expression, we have<script type="math/tex; mode=display">
\Delta^2=\frac{1}{2}\Sigma_{ij}A_{ij}(x_i^2-2x_ix_j+x_j^2)=\frac{1}{2}[\Sigma_ik_ix_i^2-2\Sigma_{ij}A_{ij}x_ix_j+\Sigma_{j}k_jx_j^2]\\
=\Sigma_{ij}(k_i\delta_{ij}-A_{ij})x_ix_j=\Sigma_{ij}L_{ij}x_ix_j</script>Equation can be written in matrix notation as<script type="math/tex; mode=display">
\Delta^2=x^TLx</script></li>
</ul>
<h4 id="19-图拉普拉斯应用——随机游走-Random-Walks"><a href="#19-图拉普拉斯应用——随机游走-Random-Walks" class="headerlink" title="19) 图拉普拉斯应用——随机游走(Random Walks)"></a>19) 图拉普拉斯应用——随机游走(Random Walks)</h4><ul>
<li><p>A <strong>random walk</strong> is a walk across a network created by taking repeated random steps. Starting at any initial node, we choose uniformly at random among the edges attached to that node, move along the chosen edge to the node at its other end, and repeat the process.</p>
</li>
<li><p>Let $p_i(t)$ be the probability that the walk is at node $i$ at time $t$. If the walk is at node $j$ at time $t−1$, the probability of taking a step along any particular one of the $k_j$ edges attached to $j$ is $\frac{1}{k_j}$ , so on an undirected network the probability of being at node $i$ on the next step is given by</p>
<script type="math/tex; mode=display">
p_i(t)=\Sigma_j\frac{A_{ij}}{k_j}p_j(t-1)</script><p>or $p(t)=AD^{−1}p(t − 1)$ in matrix form, where $p$ is the vector with elements $p_i$ and, as before, $D$ is the diagonal matrix with the degrees of the nodes down its diagonal.</p>
<p>In the limit of long time the probability distribution over nodes is given by (11) with $t$ set to infinity: $p_i(∞)=\Sigma_jA_{ij}p_i(∞)/k_j$ , or in matrix form:</p>
<script type="math/tex; mode=display">
p=AD^{-1}p</script><p>where $p$ is shorthand for $p(∞)$. Rearranging, this can also be written as</p>
<script type="math/tex; mode=display">
(I-AD^{-1})p=(D-A)D^{-1}p=LD^{-1}p=0</script><p>Thus $D^{−1p is (any multiple of) an eigenvector of the Laplacian with eigenvalue 0.</p>
<blockquote>
<p>On any given step a random walk is equally likely to traverse every edge.</p>
</blockquote>
</li>
</ul>
<h4 id="20-图拉普拉斯应用——电阻网络-Resistor-Networks"><a href="#20-图拉普拉斯应用——电阻网络-Resistor-Networks" class="headerlink" title="20) 图拉普拉斯应用——电阻网络 (Resistor Networks)"></a>20) 图拉普拉斯应用——电阻网络 (Resistor Networks)</h4><ul>
<li>Let $V_i$ be the voltage at node $i$, measured relative to any convenient reference potential. Then Kirchhoff’s law says that<script type="math/tex; mode=display">
\Sigma_jA_{ij}\frac{V_i-V_j}{R}-I_i=0</script>where $I_i$ represents any current injected into node $i$ by an external current source. In our case this external current is non-zero only for the two nodes $s$ and $t$ connected to the external voltage:<script type="math/tex; mode=display">
I_{i}=
\begin{cases}
+I & for\ i=s \\
-I & for\ i=t \\
0 & otherwise
\end{cases}</script>(14) can be written as $k_iV_i-\Sigma_jA_{ij}V-j=RI_i$ or<script type="math/tex; mode=display">
\Sigma_i(\delta_{ij}k_i-A_{ij})V_j=RI_i</script>which in matrix form is <script type="math/tex; mode=display">
LV=RI</script>where $L$ is once again the graph Laplacian. This equation is a kind of matrix version of the standard Ohm’s law $V=RI $ for a single resistor, and by solving it for $V$ we can calculate the voltages at every node in the network.</li>
</ul>
<h4 id="21-图拉普拉斯的性质-Properties"><a href="#21-图拉普拉斯的性质-Properties" class="headerlink" title="21) 图拉普拉斯的性质 (Properties)"></a>21) 图拉普拉斯的性质 (Properties)</h4><ul>
<li><p>It has the property that every row of the matrix sums to zero:</p>
<script type="math/tex; mode=display">
\Sigma_jL_{ij}=\Sigma_j(k_i\delta_{ij}-A_{ij})=k_i-k_i=0</script><p>Similarly every column of the matrix also sums to zero.         </p>
</li>
<li><p>Since the Laplacian is a real symmetric matrix, it necessarily has real eigenvalues. But we can say more than this: <strong>all the eigenvalues of the Laplacian are also non-negative.</strong></p>
<p>Let $λ$ be any eigenvalue of the graph Laplacian and let $v$ be the corresponding eigenvector, unit normalized so that $v^Tv=1$. Then $Lv=λv$ and</p>
<script type="math/tex; mode=display">
v^TLv=\lambda v^Tv=\lambda</script><p>We can write</p>
<script type="math/tex; mode=display">
\Sigma_{ij}A_{ij}(v_i-v_j)^2=\Sigma_{ij}A_{ij}(v^2_i-2v_iv_j+v_j^2)\\
=\Sigma_ik_iv_i^2-2\Sigma_{ij}A_{ij}v_iv_j+\Sigma_jk_jv_j^2\\
=2\Sigma_{ij}(k_i\delta_{ij}-A_{ij})v_iv_j=2\Sigma_{ij}L_{ij}v_iv_j=2v^TLv</script><p>We then get</p>
<script type="math/tex; mode=display">
\lambda=\frac{1}{2}\Sigma_{ij}A_{ij}(v_i-v_j)^2\ge0</script><p>Thus all eigenvalues of the Laplacian are non-negative.</p>
</li>
<li><p>In fact the Laplacian always has at least one zero eigenvalue. As we have seen, every row of the matrix sums to zero, which means that the vector <em>$1$</em>$=(1, 1, 1, . . .)$ is always an eigenvector of the Laplacian with eigenvalue zero: $L1=0.$ </p>
</li>
<li><p>The determinant of a matrix is the product of its eigenvalues, and hence the determinant of the Laplacian is always zero, so the matrix is <strong>singular</strong>.</p>
</li>
<li><p>If a network has only one component then the second smallest eigenvalue will be non-zero.</p>
</li>
<li><p>The second smallest eigenvalue of the Laplacian is called the algebraic connectivity of the network or the spectral gap.</p>
</li>
<li><p>The second smallest eigenvalue is non-zero if and only if the network is connected.</p>
</li>
<li><p>It is a straightforward extension of the same arguments to show that the number of zero eigenvalues of the Laplacian is in fact always exactly equal to the number of components in the network.</p>
</li>
</ul>
<h3 id="2-网络测度指标"><a href="#2-网络测度指标" class="headerlink" title="2. 网络测度指标"></a>2. 网络测度指标</h3><h4 id="1）中心性-Centrality"><a href="#1）中心性-Centrality" class="headerlink" title="1）中心性 (Centrality)"></a>1）中心性 (Centrality)</h4><ul>
<li>This research addresses the question, “Which are the most important or central nodes in a network?”</li>
</ul>
<h5 id="1-1-度中心性-Degree-Centrality"><a href="#1-1-度中心性-Degree-Centrality" class="headerlink" title="[1.1] 度中心性 (Degree Centrality)"></a>[1.1] 度中心性 (Degree Centrality)</h5><ul>
<li>Degree is sometimes called degree centrality in the social networks literature, to emphasize its use as a centrality measure. (social network &amp; citation network)</li>
</ul>
<h5 id="1-2-特征向量中心性-Eigenvector-Centrality"><a href="#1-2-特征向量中心性-Eigenvector-Centrality" class="headerlink" title="[1.2] 特征向量中心性 (Eigenvector Centrality)"></a>[1.2] 特征向量中心性 (Eigenvector Centrality)</h5><ul>
<li><p>In many circumstances a node’s importance in a network is increased by having connections to other nodes that are themselves important. Eigenvector centrality is an extension of degree centrality that takes this factor into account.</p>
</li>
<li><p>Consider an undirected network of n nodes. The eigenvector centrality $x_i$ of node $i$ is defined to be proportional to the sum of the centralities of $i$’s neighbors, so that</p>
<script type="math/tex; mode=display">
\begin{equation}
x_i=\kappa^{-1}\sum_{node\ j\ that\ are\ neighbors\ of\ i}x_j
\end{equation}</script><p>where we have called the constant of proportionality $\kappa^{-1}$ for reasons that will become clear. For the moment we will leave the value of $\kappa$ arbitrary—we will choose a value shortly.</p>
<p>An alternative way to write (22) is to make use of the adjacency matrix:</p>
<script type="math/tex; mode=display">
\begin{equation}
x_i=\kappa^{-1}\sum_{j=1}^{n}A_{ij}x_j
\end{equation}</script><p>This formula can also be written in matrix notation as $x=\kappa^{-1}Ax$, or equivalently</p>
<script type="math/tex; mode=display">
\begin{equation}
Ax=\kappa x
\end{equation}</script><p>where $x$ is the vector with elements equal to the centrality scores $x_i$ . In other words, $x$ is an eigenvector of the adjacency matrix.</p>
</li>
<li><p>With eigenvector centrality defined in this way, a node can achieve high centrality either by having a lot of neighbors with modest centrality, or by having a few neighbors with high centrality.</p>
</li>
<li><p>Assuming we want our centrality scores to be non-negative, there is only one choice: $x$ must be the leading eigenvector of the adjacency matrix, i.e., the eigenvector corresponding to the largest (most positive) eigenvalue.</p>
</li>
<li><strong>Perron–Frobenius theorem</strong>：for a matrix with all elements non-negative, like the adjacency matrix, there is only one eigenvector that also has all elements non-negative, and that is the leading eigenvector.Every other eigenvector must have at least one negative element.</li>
<li>This also fixes the value of the constant $\kappa$—it must be equal to the largest eigenvalue.</li>
<li>A directed network has an adjacency matrix that is, in general, asymmetric. This means it has two sets of eigenvectors, the left eigenvectors and the right eigenvectors, and hence two leading eigenvectors. Which of the two should we use to define the centrality? In most cases the correct answer is to use the right eigenvector. (The reason is that centrality in directed networks is usually bestowed by other nodes that point towards you, rather than by you pointing to others.)</li>
<li>In mathematical terms, only nodes that are in a strongly connected component of two or more nodes, or the out-component of such a strongly connected component, can have non-zero eigenvector centrality.</li>
</ul>
<h5 id="1-3-Katz中心性"><a href="#1-3-Katz中心性" class="headerlink" title="[1.3] Katz中心性"></a>[1.3] Katz中心性</h5><ul>
<li><p>We simply give each node a small amount of centrality “for free,” regardless of its position in the network or the centrality of its neighbors. In other words, we define</p>
<script type="math/tex; mode=display">
\begin{equation}
x_i=\alpha \sum_jA_{ij}x_j+\beta
\end{equation}</script><p>where α and β are positive constants. The first term is the normal eigenvector centrality term in which the centralities of the nodes pointing to i are summed, and the second term is the “free” part, the constant extra amount that all nodes receive.</p>
<p>In matrix terms, it can be written</p>
<script type="math/tex; mode=display">
x=\alpha Ax+\beta 1</script><p>Rearrangeing for x, we then find that </p>
<script type="math/tex; mode=display">
x=\beta (I-\alpha A)^{-1}1</script><p>For convenience we usually set $\beta=1$, giving</p>
<script type="math/tex; mode=display">
x=(I-\alpha A)^{-1}1</script><p>The definition of the Katz centrality contains the parameter $\alpha$, which governs the balance between the eigenvector centrality term and the constant term. </p>
</li>
<li><p>Most researchers have employed values($\alpha$) close to the maximum of $1/ \kappa_1$, which places the maximum amount of weight on the eigenvector term and the smallest amount on the constant term.</p>
</li>
<li>It allows a node that has many neighbors to have high centrality regardless of whether those neighbors themselves have high centrality, and this could be useful in some applications.</li>
</ul>
<h5 id="1-4-PageRank"><a href="#1-4-PageRank" class="headerlink" title="[1.4] PageRank"></a>[1.4] PageRank</h5><ul>
<li><p>In many cases it means less if a node is only one among many that are pointed to. The centrality gained by virtue of receiving an edge from a prestigious node is diluted by being shared with so many others.</p>
</li>
<li><p>We can allow for this by defining a variant of the Katz centrality in which the centrality I derive from my network neighbors is proportional to their centrality divided by their out-degree. Then nodes that point to many others pass only a small amount of centrality on to each of those others, even if their own centrality is high. In mathematical terms this centrality is defined by</p>
<script type="math/tex; mode=display">
x_i=\alpha\sum_jA_{ij}\frac{x_j}{k_j^{out}}+\beta</script><p>In matrix terms, it is then</p>
<script type="math/tex; mode=display">
x=\alpha AD^{-1}x+\beta 1</script><p>with $1$ being again the vector $(1, 1, 1, . . .)$ and $D$ being the diagonal matrix with elements $D_{ii}=max(k^{out}_i , 1)$. Rearranging, we find that $x=\beta (I-\alpha AD^{-1})^{-1}1$, and thus, as before, $\beta$ plays the role only of an unimportant overall multiplier for the centrality. Conventionally, we set $\beta=1$, giving</p>
<script type="math/tex; mode=display">
x=(I-\alpha AD^{-1})^{-1}1</script><p>This centrality measure is commonly known as PageRank, which is a name given it by the Google web search corporation. We can see that the value of $\alpha$ should be less than the inverse of the largest eigenvalue of $AD^{−1}$. For an undirected network this largest eigenvalue turns out to be one, and thus $\alpha$ should be less than one.</p>
</li>
</ul>
<h5 id="1-5-Hubs-and-Authorities"><a href="#1-5-Hubs-and-Authorities" class="headerlink" title="[1.5] Hubs and Authorities"></a>[1.5] Hubs and Authorities</h5><ul>
<li><p><strong>Authorities</strong> are nodes that contain useful information on a topic of interest and hubs are nodes that tell us where the best authorities are to be found.</p>
</li>
<li><p>The concept of hubs and authorities in networks was first put forward by Kleinberg  and developed by him into a centrality algorithm called hyperlink-induced topic search or HITS. The HITS algorithm gives each node $i$ in a directed network two different centrality scores, the authority centrality $x_i$ and the hub centrality $y_i$ , which quantify nodes’ prominence in the two roles. The defining characteristic of a node with high authority centrality is that it is pointed to by many nodes with high hub centrality. Conversely, the defining characteristic of a node with high hub centrality is that it points to many nodes with high authority centrality.</p>
</li>
<li><p>In Kleinberg’s approach the authority centrality of a node is defined to be proportional to the sum of the hub centralities of the nodes that point to it:</p>
<script type="math/tex; mode=display">
x_i=\alpha \sum_jA_{ij}y_j</script><p>where $\alpha$ is a constant. Similarly, the hub centrality of a node is proportional to the sum of the authority centralities of the nodes it points to:</p>
<script type="math/tex; mode=display">
y_i=\beta \sum_jA_{ji}x_j</script><p>with $\beta$ another constant. Note that the indices on the matrix element $A_{ji}$ are swapped around in this second equation: it is the nodes that $i$ points to that define its hub centrality.</p>
<p>In matrix terms these equations can be written as</p>
<script type="math/tex; mode=display">
x=\alpha Ay\\
y=\beta A^Tx</script><p>or, combining the two,</p>
<script type="math/tex; mode=display">
AA^Tx=\lambda x</script><p>and</p>
<script type="math/tex; mode=display">
A^TAy=\lambda y</script><p>where $\lambda=(\alpha \beta)^{-1}$. Thus the authority and hub centralities are respectively given by eigenvectors of $AA^T$ and $A^TA$ with the same eigenvalue. It is easily proved, however, that this is the case, and in fact that all eigenvalues are the same for the two matrices. (p169)</p>
</li>
<li><p>In the hub and authority approach nodes not cited by any others have authority centrality zero (which is reasonable), but they can still have non-zero hub centrality.</p>
</li>
</ul>
<h5 id="1-6-接近度中心性-Closeness-Centrality"><a href="#1-6-接近度中心性-Closeness-Centrality" class="headerlink" title="[1.6] 接近度中心性 (Closeness Centrality)"></a>[1.6] 接近度中心性 (Closeness Centrality)</h5><ul>
<li><p>The mean shortest distance from $i$ to every node in the network is</p>
<script type="math/tex; mode=display">
l_i=\frac{1}{n}\sum_jd_{ij}</script><p>The inverse of $l_i$ is called the <em>closeness centrality</em></p>
<script type="math/tex; mode=display">
C_i=\frac{1}{l_i}=\frac{n}{\sum_jd_{ij}}</script></li>
<li><p>One protential problem with the definition of closeness centrality concerns networks that have more than one component. Perhaps a better solution is to redefine closeness in terms of the harmonic mean distance between nodes, i.e., the average of the inverse distances:</p>
<script type="math/tex; mode=display">
C_i^{\prime}=\frac{1}{n-1}\sum_{j(\ne i)}\frac{1}{d_{ij}}</script><p>First, if $d_{ij}=\infty$ because $i$ and $j$ are in different components, then the corresponding term in the sum is simply zero and drops out. Second, the measure naturally gives more weight to nodes that are close to $i$ than to those far away.</p>
</li>
</ul>
<h5 id="1-7-介数中心性-Betweenness-Centrality"><a href="#1-7-介数中心性-Betweenness-Centrality" class="headerlink" title="[1.7] 介数中心性 (Betweenness Centrality)"></a>[1.7] 介数中心性 (Betweenness Centrality)</h5><ul>
<li><p>Betweenness centrality may still be a reasonable guide to the influence nodes have over the flow of information between others.</p>
</li>
<li><p>Let $n^i_{st}$ be 1 if node $i$ lies on the shortest path from $s$ to $t$ and 0 if it does not or if there is no such path. Then the betweenness centrality $x_i$ is given by</p>
<script type="math/tex; mode=display">
x_i=\sum_{st}n^i_{st}</script><p>Note that this definition counts separately the shortest paths in either direction between each node pair.</p>
</li>
<li><p>Extension:if there are two shortest paths between a given pair of nodes, each of them gets weight $\frac{1}{2}$. Then the betweenness of a node is defined to be the sum of the weights of all shortest paths passing through that node.</p>
</li>
<li><p>If two or more paths pass through the same node then the betweenness sum includes contributions from each of them.</p>
</li>
<li><p>We redefine $n^i_{st}$ to be the number of shortest paths from $s$ to $t$ that pass through $i$ and we define $g_{st}$ to be the total number of shortest paths from $s$ to $t$. Then the betweenness centrality of node $i$ on a general network is</p>
<script type="math/tex; mode=display">
x_i=\sum_{st}\frac{n^i_{st}}{g_{st}}</script><p>where we adopt the convention that $n^i_{st}/g_{st}$ if both $n^i_{st}$ and $g_{st}$ are zero.</p>
</li>
<li><p>Betweenness centrality differs from the other centrality measures we have considered in being not principally a measure of how well-connected a node is. Instead it measures how much a node falls “between” others.</p>
</li>
<li><p>One natural choice is to normalize the path count by dividing by the total number of (ordered) node pairs, which is $n^2$, so that betweenness becomes the fraction (rather than the number) of paths that run through a given node:</p>
<script type="math/tex; mode=display">
x_i=\frac{1}{n^2}\sum_{st}\frac{n^i_{st}}{g_{st}}</script><p>With this definition, the values of the betweenness lie strictly between zero and one.</p>
</li>
<li><p><em>Flow betweenness</em> is a variant of betweenness centrality that uses edge-in- dependent paths between node pairs rather than shortest paths.</p>
</li>
<li><p>Another variant is <em>random-walk betweenness</em>, which imagines messages performing random walks across the network between every possible starting point and destination, and the betweenness is defined as the average number of such messages that pass through each node.</p>
</li>
</ul>
<h4 id="2）节点组-Groups-Of-Nodes"><a href="#2）节点组-Groups-Of-Nodes" class="headerlink" title="2）节点组 (Groups Of Nodes)"></a>2）节点组 (Groups Of Nodes)</h4><ul>
<li>In this section we discuss some simpler concepts of network groups that can be useful for probing and describing the local structure of networks. The primary constructs we look at are cliques, <em>k</em>-cores, and <em>k</em>-components.</li>
</ul>
<h5 id="2-1-团-Cliques"><a href="#2-1-团-Cliques" class="headerlink" title="[2.1] 团 (Cliques)"></a>[2.1] 团 (Cliques)</h5><ul>
<li>A <em>clique</em> is a set of nodes within an undirected network such that every member of the set is connected by an edge to every other.</li>
<li>The one-mode projection creates a network that is naturally composed of cliques.</li>
</ul>
<h5 id="2-2-核-Cores"><a href="#2-2-核-Cores" class="headerlink" title="[2.2] 核 (Cores)"></a>[2.2] 核 (Cores)</h5><ul>
<li><em>k</em>-core is a connected set of nodes where each is joined to at least <em>k</em> of the others. </li>
<li>A simple way to find them is to start with a given network and remove from it any nodes that have degree less than <em>k</em>, along with their attached edges, since clearly such nodes cannot under any circumstances be members of a <em>k</em>-core. In so doing, one will normally reduce the degrees of some other nodes in the network—those that were connected to the nodes just removed. So we then go through the network again to see if there are any additional nodes that now have degree less than <em>k</em> and remove those too. And so we proceed, repeatedly pruning the network to remove nodes with degree less than <em>k</em> until no such nodes remain. What is left over will, by definition, be a <em>k</em>-core or a set of <em>k</em>-cores, since each node is connected to at least <em>k</em> others. Note that we are not necessarily left with a <em>single</em> <em>k</em>-core—there’s no guarantee that the network will be connected once we are done pruning it, even if it was connected to start with.</li>
</ul>
<h5 id="2-3-连通块与k连通块-Components-amp-k-Components"><a href="#2-3-连通块与k连通块-Components-amp-k-Components" class="headerlink" title="[2.3] 连通块与k连通块 (Components &amp; k-Components)"></a>[2.3] 连通块与k连通块 (Components &amp; k-Components)</h5><ul>
<li>A <em>k-component</em> (sometimes also called a <em>k-connected component</em>) is a set of nodes such that each is reachable from each of the others by at least <em>k</em> node-independent paths.</li>
<li><em>k</em>-components are nested within each other.</li>
<li>So another way of defining a <em>k</em>-component would be to say that it is a subset of a network in which no pair of nodes can be disconnected from each other by removing less than <em>k</em> other nodes.</li>
<li>One disadvantage of <em>k</em>-components as a definition of node groups, is that for $k\ge3$ they can be non-contiguous.</li>
<li><em>k</em>-components are sometimes defined slightly differently, to be a set of nodes such that every pair in the set is connected by at least <em>k</em> node-independent paths <em>that themselves are contained entirely within the subset</em>.</li>
</ul>
<h4 id="3-传递性-Transitivity-与聚类系数-Clustering-Coefficient"><a href="#3-传递性-Transitivity-与聚类系数-Clustering-Coefficient" class="headerlink" title="3) 传递性(Transitivity)与聚类系数(Clustering Coefficient)"></a>3) 传递性(Transitivity)与聚类系数(Clustering Coefficient)</h4><p>​    </p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Peyton</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://peyton.github.io/2022/07/21/network-xue-xi-bi-ji/">https://peyton.github.io/2022/07/21/network-xue-xi-bi-ji/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">Peyton</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Network-Science/">
                                    <span class="chip bg-color">Network Science</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/2022/07/21/network-xue-xi-bi-ji/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/11.jpg" class="responsive-img" alt="Networks学习笔记">
                        
                        <span class="card-title">Networks学习笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-07-21
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Network-Science/" class="post-category">
                                    Network Science
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Network-Science/">
                        <span class="chip bg-color">Network Science</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2022/07/10/2022-nian-qing-bo-ben-hui-zong/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/1.jpg" class="responsive-img" alt="2022年轻薄本汇总">
                        
                        <span class="card-title">2022年轻薄本汇总</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-07-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E7%94%B5%E8%84%91%E6%B5%8B%E8%AF%84/" class="post-category">
                                    电脑测评
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E7%94%B5%E8%84%91%E6%B5%8B%E8%AF%84/">
                        <span class="chip bg-color">电脑测评</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    

    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2022</span>
            
            <span id="year">2019</span>
            <a href="/about" target="_blank">Peyton</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">58.5k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2019";
                    var startMonth = "09";
                    var startDate = "20";
                    var startHour = "0";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Peyton-Chen" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1127287784@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1127287784" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1127287784" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
    $(function () {
        var searchFunc = function (path, search_id, content_id) {
            'use strict';
            $.ajax({
                url: path,
                dataType: "xml",
                success: function (xmlResponse) {
                    // get the contents from search data
                    var datas = $("entry", xmlResponse).map(function () {
                        return {
                            title: $("title", this).text(),
                            content: $("content", this).text(),
                            url: $("url", this).text()
                        };
                    }).get();
                    var $input = document.getElementById(search_id);
                    var $resultContent = document.getElementById(content_id);
                    $input.addEventListener('input', function () {
                        var str = '<ul class=\"search-result-list\">';
                        var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                        $resultContent.innerHTML = "";
                        if (this.value.trim().length <= 0) {
                            return;
                        }
                        // perform local searching
                        datas.forEach(function (data) {
                            var isMatch = true;
                            var data_title = data.title.trim().toLowerCase();
                            var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                            var data_url = data.url;
                            data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                            var index_title = -1;
                            var index_content = -1;
                            var first_occur = -1;
                            // only match artiles with not empty titles and contents
                            if (data_title !== '' && data_content !== '') {
                                keywords.forEach(function (keyword, i) {
                                    index_title = data_title.indexOf(keyword);
                                    index_content = data_content.indexOf(keyword);
                                    if (index_title < 0 && index_content < 0) {
                                        isMatch = false;
                                    } else {
                                        if (index_content < 0) {
                                            index_content = 0;
                                        }
                                        if (i === 0) {
                                            first_occur = index_content;
                                        }
                                    }
                                });
                            }
                            // show search results
                            if (isMatch) {
                                str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                                var content = data.content.trim().replace(/<[^>]+>/g, "");
                                if (first_occur >= 0) {
                                    // cut out 100 characters
                                    var start = first_occur - 20;
                                    var end = first_occur + 80;
                                    if (start < 0) {
                                        start = 0;
                                    }
                                    if (start === 0) {
                                        end = 100;
                                    }
                                    if (end > content.length) {
                                        end = content.length;
                                    }
                                    var match_content = content.substr(start, end);
                                    // highlight all keywords
                                    keywords.forEach(function (keyword) {
                                        var regS = new RegExp(keyword, "gi");
                                        match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                    });

                                    str += "<p class=\"search-result\">" + match_content + "...</p>"
                                }
                                str += "</li>";
                            }
                        });
                        str += "</ul>";
                        $resultContent.innerHTML = str;
                    });
                }
            });
        };

        searchFunc('/search.xml', 'searchInput', 'searchResult');
    });
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    
    
    <script type="text/javascript" size="150" alpha='0.8'
        zIndex="-1" src="/libs/background/ribbon-refresh.min.js" async="async"></script>
    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    
<script type="text/javascript">
//只在桌面版网页启用特效
var windowWidth = $(window).width();
if (windowWidth > 768) {
    document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>');
}
</script>
<script src="/js/cursor.js"></script>
</body>

</html>
